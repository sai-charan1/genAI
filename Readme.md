# GenAI Assignment â€“ Internal AI Analyst (DeepAgents + RAG) ğŸš€

An **end-to-end Retrieval-Augmented Generation (RAG) system** built using a **DeepAgents multi-agent workflow** to analyze **policy documents, product manuals, and financial reports** at enterprise scale.

This project demonstrates **production-grade GenAI system design**, covering document ingestion, hybrid retrieval, multi-agent orchestration, grounded answer generation, and quantitative evaluation.

---

## ğŸ¯ What This Project Does

1. Uploads **20+ PDFs** (policy, manuals, financial reports) via a **Streamlit UI**
2. Performs **semantic chunking** â†’ **HuggingFace embeddings** â†’ **Chroma vector store**
3. Executes **hybrid retrieval** (Vector + BM25 + Re-ranking) with **top-5 chunks + diagnostics**
4. Uses a **DeepAgents 3-agent workflow** to generate **structured, grounded JSON answers**
5. Displays **answer, evidence, retrieved chunks, confidence, and latency metrics** in the UI

---

## ğŸ“ Project Structure

```
genai-analyst/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ supervisor_agent.py      # DeepAgents supervisor + 3 sub-agents
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ingestion.py             # PDF loading + semantic chunking + embeddings
â”‚   â””â”€â”€ retrieval.py             # Hybrid Retriever (Vector + BM25 + Re-rank)
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_type_classifier_prompt.py
â”‚   â”œâ”€â”€ answer_generation_prompt.py
â”‚   â””â”€â”€ summarization_prompt.py
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ui_streamlit.py           # Streamlit UI
â”œâ”€â”€ eval/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluation.py             # Hallucination, precision/recall, latency
â”‚   â”œâ”€â”€ hallucination_data.json
â”‚   â””â”€â”€ test_data.json
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eval_notebook.ipynb       # Evaluation runner
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Input PDFs (20+ documents)
â”‚   â””â”€â”€ chroma_db/                # Vector store (auto-generated)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ Dockerfile                    # Optional containerized deployment
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start (5 Minutes)

### 1ï¸âƒ£ Clone & Setup Environment

```bash
git clone <your-repo>
cd genai-analyst
python -m venv .venv
```

**Windows**
```bash
.venv\Scriptsctivate
```

**Linux / macOS**
```bash
source .venv/bin/activate
```

---

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Configure Azure OpenAI (Optional)

```bash
cp .env.example .env
```

Edit `.env`:

```env
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=your-deployment-name
AZURE_OPENAI_API_VERSION=2024-02-01
AZURE_OPENAI_API_KEY=your-api-key
```

> The system also works with local / open-source LLMs if Azure OpenAI is not configured.

---

### 4ï¸âƒ£ Add PDFs (20+ Documents)

```
data/raw/
â”œâ”€â”€ policy_docs/         # EURLEX, Federal Register
â”œâ”€â”€ financial_reports/   # SEC 10-K / 10-Q filings
â””â”€â”€ manuals/             # Appliance / equipment manuals
```

Each document should ideally be **25+ pages** to simulate enterprise-scale data.

---

### 5ï¸âƒ£ Run the Streamlit UI

```bash
streamlit run app/ui_streamlit.py
```

Open in browser:  
ğŸ‘‰ **http://localhost:8501**

---

## ğŸ® How to Use the Application

### Step 1: Upload Documents
- Sidebar â†’ Upload PDFs â†’ **Build Index**
- Pipeline executed:
  - PyPDFLoader
  - Semantic chunking
  - HuggingFace embeddings
  - Chroma indexing

**Example Log**
```
Indexed 125 chunks from 5 files
```

---

### Step 2: Ask Questions

Example:
```
How do I start the washing machine?
```

Click **Run Analysis**

---

### Step 3: View Results (Exact Order)

1. **Answer**
2. **Evidence Used** (source + snippet + relevance score)
3. **Top-5 Retrieved Chunks** (doc_id, score, full text)
4. **Missing Information** (if context is insufficient)
5. **Confidence Score**
6. **Latency & Raw Diagnostics** (expandable section)

---

## ğŸ—ï¸ Technical Architecture

### 1ï¸âƒ£ RAG Pipeline (`ingestion/`)

```
PDF Loader
â†’ Semantic Chunking
â†’ HF Embeddings (all-mpnet-base-v2)
â†’ Chroma Vector Store
â†’ Hybrid Retrieval
```

### Hybrid Retrieval Strategy

- **Vector Search**: Chroma similarity (+2.0 weight)
- **BM25 Search**: Keyword relevance (+1.0 weight)
- **Re-ranking**: Sorted combined scores

**Output**:  
Top-5 `{source, text, score}` + retrieval diagnostics

---

### 2ï¸âƒ£ DeepAgents Workflow (`agents/supervisor_agent.py`)

```
Supervisor Agent
â”‚
â”œâ”€â”€ Query Analyzer Agent
â”‚   - Intent classification
â”‚   - Query rewriting
â”‚   - Retrieval strategy selection
â”‚
â”œâ”€â”€ Retrieval Agent
â”‚   - Hybrid vector + BM25 search
â”‚   - Evidence selection
â”‚
â””â”€â”€ Answer Agent
    - Evidence-grounded reasoning
    - Strict JSON schema enforcement
```

**Final Output Schema**
```json
{
  "answer": "...",
  "evidence_used": [...],
  "top_chunks": [...],
  "confidence": 0.85
}
```

---

### 3ï¸âƒ£ Prompt Design (`prompts/`)

- **Document Type Classifier**
  - Policy / Manual / Financial / General
- **Answer Generation Prompt**
  - JSON-only output
  - No unsupported claims
- **Summarization Prompt**
  - RAG-optimized, entity-preserving

---

## ğŸ“Š Evaluation & Metrics (`eval/`)

Run evaluation notebook:

```bash
jupyter notebook notebooks/eval_notebook.ipynb
```

### Metrics Computed

| Metric | Description | Result |
|------|------------|--------|
| Hallucination Rate | Unsupported answers | **10%** |
| Precision | Relevant retrieved chunks | **0.85** |
| Recall | Gold chunk coverage | **0.78** |
| Latency | End-to-end response | **230 ms avg** |
| Embedding Quality | Pos/Neg similarity | **0.78 / 0.12** |

---

## âœ… Key Design Decisions

- Hybrid retrieval improves recall over pure vector search
- DeepAgents enable separation of reasoning responsibilities
- Strict JSON schemas reduce hallucinations
- Evidence-first UI improves trust and auditability
- Evaluation is integrated, not post-hoc

---

